{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec93e42-6775-43e9-95bf-3040065e02a0",
   "metadata": {},
   "source": [
    "# NanoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7eb3997-b3d7-42db-842d-32548bf76ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('tiny_shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39554f26-c0b1-47af-b329-c6e9bc63db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0dc2533-34c4-40fe-b41f-b225db608918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14169e23-f8b8-46d8-b4a7-0852e73d4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "703698f5-0655-477c-82ad-6096737b117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch: i for i, ch in enumerate(chars) }\n",
    "itos = { i: ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7dcc8427-d164-4c08-84d9-e83fd22a0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b143515-3e06-4f33-a174-17fc442a1f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b9c0f1f-fc12-4db2-94fa-1cd41dc96ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30a63698-a00b-4e1d-9075-2f39a4ded183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # context length\n",
    "train_data[:block_size+1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cf99df3-3aad-44c2-8d1a-fa29992efd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]), the target is: 47\n",
      "When input is tensor([18, 47]), the target is: 56\n",
      "When input is tensor([18, 47, 56]), the target is: 57\n",
      "When input is tensor([18, 47, 56, 57]), the target is: 58\n",
      "When input is tensor([18, 47, 56, 57, 58]), the target is: 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]), the target is: 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is: 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is: 58\n"
     ]
    }
   ],
   "source": [
    "# In a chunk of 9 characters, there are 8 individual training examples that get sent to the network.\n",
    "# This also helps the network to see different context sizes, from 1 to block_size. This allows the network to learn how to predict in multiple context lengths.\n",
    "# Let's take a look. \n",
    "X = train_data[:block_size]\n",
    "Y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = X[:t+1]\n",
    "    target = Y[t]\n",
    "    print(f\"When input is {context}, the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb100569-b3fb-4baa-bf97-e8863cf6e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "Targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "---\n",
      "When input is tensor([24]), the target is: 43\n",
      "When input is tensor([24, 43]), the target is: 58\n",
      "When input is tensor([24, 43, 58]), the target is: 5\n",
      "When input is tensor([24, 43, 58,  5]), the target is: 57\n",
      "When input is tensor([24, 43, 58,  5, 57]), the target is: 1\n",
      "When input is tensor([24, 43, 58,  5, 57,  1]), the target is: 46\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46]), the target is: 43\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46, 43]), the target is: 39\n",
      "When input is tensor([44]), the target is: 53\n",
      "When input is tensor([44, 53]), the target is: 56\n",
      "When input is tensor([44, 53, 56]), the target is: 1\n",
      "When input is tensor([44, 53, 56,  1]), the target is: 58\n",
      "When input is tensor([44, 53, 56,  1, 58]), the target is: 46\n",
      "When input is tensor([44, 53, 56,  1, 58, 46]), the target is: 39\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39]), the target is: 58\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39, 58]), the target is: 1\n",
      "When input is tensor([52]), the target is: 58\n",
      "When input is tensor([52, 58]), the target is: 1\n",
      "When input is tensor([52, 58,  1]), the target is: 58\n",
      "When input is tensor([52, 58,  1, 58]), the target is: 46\n",
      "When input is tensor([52, 58,  1, 58, 46]), the target is: 39\n",
      "When input is tensor([52, 58,  1, 58, 46, 39]), the target is: 58\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58]), the target is: 1\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58,  1]), the target is: 46\n",
      "When input is tensor([25]), the target is: 17\n",
      "When input is tensor([25, 17]), the target is: 27\n",
      "When input is tensor([25, 17, 27]), the target is: 10\n",
      "When input is tensor([25, 17, 27, 10]), the target is: 0\n",
      "When input is tensor([25, 17, 27, 10,  0]), the target is: 21\n",
      "When input is tensor([25, 17, 27, 10,  0, 21]), the target is: 1\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1]), the target is: 54\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1, 54]), the target is: 39\n"
     ]
    }
   ],
   "source": [
    "# For efficiency purposes, we'll add an extra \"batch\" dimension to take advantage of GPU parallelism\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) -  block_size, (batch_size, )) # 4 numbers randomly generated between 0 and len(data) -  block_size\n",
    "    x = torch.stack([data[i: i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1: i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"Inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print(\"---\")\n",
    "\n",
    "# The total number of examples here would be 8 x 4 = 32 independent examples, packed into a single batch x with targets y, which will all be simultaneously processed by the transformers\n",
    "for b in range(batch_size): # batch dim\n",
    "    for t in range(block_size): # time dim (context length)\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context}, the target is: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72efe6-9408-4616-9e52-3c5329c9121f",
   "metadata": {},
   "source": [
    "## Simplest version: Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d5f1a58-c2f1-477b-a4e3-e0145ca19070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(5.0364, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "lfJeukRuaRJKXAYtXzfJ:HEPiu--sDioi;ILCo3pHNTmDwJsfheKRxZCFs\n",
      "lZJ XQc?:s:HEzEnXalEPklcPU cL'DpdLCafBheH\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B, T) tensor of integers where B = Batch size (4) and T = Time/Context Size (8)\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) where C is channel/embedding dimension (vocab size, 65)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # reshape the logits tensor so that it is (B*T, C) because PyTorch expects the channel dimension to be the second dimension\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "        \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        # Generate (B, T + 1), (B, T + 2), ... (B, T + max_new_tokens)\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            \n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # Becomes (B, C)\n",
    "            \n",
    "            # convert to probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            \n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T + 1)\n",
    "        \n",
    "        return idx\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# First result is random if it's not trained\n",
    "print(decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ad63888-e141-43a8-905a-e9a6f25d0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4eded4a2-c865-4047-80a0-d8de0ba8dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.362440586090088\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13c500a9-c1c8-4aa1-99d8-aa83f3954046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M:\n",
      "IUSh t,\n",
      "F th he d ke alved.\n",
      "Thupld, cipbll t\n",
      "I: ir w, l me sie hend lor ito'l an e\n",
      "\n",
      "I:\n",
      "Gochosen ea ar btamandd halind\n",
      "Aust, plt t wadyotl\n",
      "I bel qunganonoth he m he de avellis k'l, tond soran:\n",
      "\n",
      "WI he toust are bot g e n t s d je hid t his IAces I my ig t\n",
      "Ril'swoll e pupat inouleacends-athiqu heame\n"
     ]
    }
   ],
   "source": [
    "# This is a very simple model because we're only looking at the last character to see what the next character will be!\n",
    "print(decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b9e61-14f6-4f71-b760-8ffac43efb4e",
   "metadata": {},
   "source": [
    "## Self-attention: The mathematical trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28c42fc3-5ee2-4528-bee0-b14cc11134a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting with a toy example\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd016f-64d8-44a9-8748-b3f42ec6da2d",
   "metadata": {},
   "source": [
    "We want tokens to talk to each other (couple-them)\n",
    "\n",
    "For example: The token at the 5th location should communicate to tokens in previous locations, and NOT from tokens in \"future\" locations.\n",
    "\n",
    "Information should only flow in one direction.\n",
    "\n",
    "How to do this? I'd like to average the features on tokens 1-5, which would represent a summary of the fifth token in the context of its history (tokens 1-4).\n",
    "\n",
    "A downside is that we'd lose a lot of information by compressing all the tokens like that but we'll worry about that later.\n",
    "\n",
    "For now, \n",
    "\n",
    "```\n",
    "for every batch:\n",
    "    for every t-th token in that sequence:\n",
    "        calculate the average of all the tokens up to the current one.\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ff3f99d-f4f7-4485-aa94-5a2fae2389eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want: x[b, t] = mean_{i <= t} x[b_i]\n",
    "xbow = torch.zeros((B, T, C)) # bow = bag of words, term to mean \"averaging\". I wish we would call this x_mean haha\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29058cc5-e265-4ed5-a4e3-bb47d052a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "a=tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# but there's a more efficient way of doing this! Cool matrix multiplication trick :) \n",
    "# let's see it in an example\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# This generates a \"triangular\" matrix where the lower triangle (including the diagonal) contains ones and the upper one contains zeros\n",
    "# (Specifically, torch.tril zeros out the upper triangular part of the matrix)\n",
    "# Why is this useful? Consider the case where you multiply/dot product this matrix A (of shape m x n) by another matrix B (of shape n x k)\n",
    "# Every column in the resulting matrix will contain:\n",
    "# C[i, j] = A[i] @ B[j]\n",
    "# Which translated to our problem, it basically means we have added up all the values of column j of matrix B up to current row i (which would be \"t\")\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "print(f\"{a=}\")\n",
    "\n",
    "# and then we can divide it by the number of rows we're adding up (normalizing so all the rows add up to 1) :O :O genius\n",
    "# somehow this results in an average. I still need to internalize it but it's cool.\n",
    "# intuition: averaging ~= normalization? NO! \n",
    "# when we divide a sum of numbers by a constant C, that is the same as multiplying each of those numbers by 1/C!!!!!! LMAOOOO and each row in this triangular matrix contains the 1/C \"weight\" to multiply the list of numbers by. BAM!!\n",
    "# -> how much is each value contributing to the final average value... the \"weight\" of each number in matrix B is defined in matrix A!\n",
    "a = a / torch.sum(a, dim=1, keepdim=True)\n",
    "print(f\"{a=}\")\n",
    "print(f\"---\")\n",
    "\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "print(f\"{b=}\")\n",
    "print(f\"---\")\n",
    "\n",
    "c = a @ b\n",
    "print(f\"{c=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58cdf416-c764-4eb2-97f0-bb6103ce26c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights=tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok, then let's vectorize our operation: x[b, t] = mean_{i <= t} x[b_i]\n",
    "# REMEMBER, the goal here is that a token in the t-th position only gets information from all the tokens preceding it! \n",
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "print(f\"{weights=}\")\n",
    "\n",
    "\n",
    "# (T, T) @ (B, T, C) -- add a batch dim --> (B, T, T) @ (B, T, C) = (B, T, C)\n",
    "xbow2 = weights @ x \n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49a2853f-ec41-419a-853b-be2048adf29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tril: \n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Weights before masking: \n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Weights after masking: \n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Weights after softmax: \n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lastly, another way of doing this would be... THE SOFTMAX!!!!!!!\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# INTERPRETATION PT 1: Weights begin at 0, which represent interaction strength/affinity. How much of each token from the past do we want to aggregate/average up? \n",
    "#     At the beginning, all tokens can communicate with all tokens, but each of them has an \"affinity\" of zero to the current token\n",
    "weights = torch.zeros((T, T))\n",
    "\n",
    "# Make all the zeros in the upper triangular part of the matrix to be negative infinity because...\n",
    "print(f\"Tril: \\n{tril}\")\n",
    "print(f\"Weights before masking: \\n{weights}\")\n",
    "\n",
    "# INTERPRETATION PT 2: This is limiting communication to tokens from the past by making all tokens from the future of the current token to have an affinity of negative infinity (So we WON'T aggregate ANYTHING from those tokens).\n",
    "weights = weights.masked_fill(tril == 0, float(\"-inf\"))\n",
    "print(f\"Weights after masking: \\n{weights}\")\n",
    "\n",
    "# ... softmax will convert those to zero, and then it will normalize each row in the lower triangular part of the matrix :O :O :O \n",
    "# INTERPRETATION PT 3: This sets the amount of \"affinity\" that each token from the past will have when they get aggregated/averaged up, and for now each past token has an equal amount of \"affinity\" to the current token, which is 1/T (where T is the index of the current token)\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "print(f\"Weights after softmax: \\n{weights}\")\n",
    "\n",
    "# INTERPRETATION PT 4: Here is where we aggregate the tokens with the affinity matrix/weights, which will end up being a reflection of how \"interesting\" each token finds each other (for now, equally interesting)\n",
    "xbow3 = weights @ x\n",
    "torch.allclose(xbow, xbow3)\n",
    "\n",
    "\n",
    "# CONCLUSION: You can do weighted aggregation of your past elements by doing matrix multiplication of a lower-triangular fashion, where the elements of the lower triangular part of the matrix tell you how much of each element \"fuses\" into the current token/position\n",
    "# TRIPLE BAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3a47a-dbf6-4431-88f4-1c1f9cb222e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05e8ca-3700-4fd6-94c8-531d596c4bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
